{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CellStrat Hub Pack - Deep Learning\n",
    "\n",
    "#### DL10 - Gradient Boosted Decision Tree (GBDT)\n",
    "\n",
    "Implement a Gradient Boosted Decision Tree (GBDT) with TensorFlow. This example is using the Boston Housing Value dataset as training samples. The example supports both Classification (2 classes: value > $23000 or not) and Regression (raw home value as target).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston Housing Dataset\n",
    "\n",
    "**Link:** https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html\n",
    "\n",
    "**Description:**\n",
    "\n",
    "The dataset contains information collected by the U.S Census Service concerning housing in the area of Boston Mass. It was obtained from the StatLib archive (http://lib.stat.cmu.edu/datasets/boston), and has been used extensively throughout the literature to benchmark algorithms. However, these comparisons were primarily done outside of Delve and are thus somewhat suspect. The dataset is small in size with only 506 cases.\n",
    "\n",
    "The data was originally published by Harrison, D. and Rubinfeld, D.L. `Hedonic prices and the demand for clean air', J. Environ. Economics & Management, vol.5, 81-102, 1978.`\n",
    "\n",
    "*For the full features list, please see the link above*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# Ignore all GPUs (current TF GBDT does not support GPU).\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters.\n",
    "num_classes = 2 # Total classes: greater or equal to $23,000, or not (See notes below).\n",
    "num_features = 13 # data features size.\n",
    "\n",
    "# Training parameters.\n",
    "max_steps = 800\n",
    "batch_size = 256\n",
    "learning_rate = 1.0\n",
    "l1_regul = 0.0\n",
    "l2_regul = 0.1\n",
    "\n",
    "# GBDT parameters.\n",
    "num_batches_per_layer = 1000\n",
    "num_trees = 10\n",
    "max_depth = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Prepare Boston Housing Dataset.\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "# For classification purpose, we build 2 classes: price greater or lower than $23,000\n",
    "def to_binary_class(y):\n",
    "    for i, label in enumerate(y):\n",
    "        if label >= 23.0:\n",
    "            y[i] = 1\n",
    "        else:\n",
    "            y[i] = 0\n",
    "    return y\n",
    "\n",
    "y_train_binary = to_binary_class(copy.deepcopy(y_train))\n",
    "y_test_binary = to_binary_class(copy.deepcopy(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBDT Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/util/lazy_loader.py:63: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build the input function.\n",
    "train_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': x_train}, y=y_train_binary,\n",
    "    batch_size=batch_size, num_epochs=None, shuffle=True)\n",
    "test_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': x_test}, y=y_test_binary,\n",
    "    batch_size=batch_size, num_epochs=1, shuffle=False)\n",
    "test_train_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': x_train}, y=y_train_binary,\n",
    "    batch_size=batch_size, num_epochs=1, shuffle=False)\n",
    "# GBDT Models from TF Estimator requires 'feature_column' data format.\n",
    "feature_columns = [tf.feature_column.numeric_column(key='x', shape=(num_features,))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpejokbny3\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpejokbny3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "gbdt_classifier = tf.estimator.BoostedTreesClassifier(\n",
    "    n_batches_per_layer=num_batches_per_layer,\n",
    "    feature_columns=feature_columns, \n",
    "    n_classes=num_classes,\n",
    "    learning_rate=learning_rate, \n",
    "    n_trees=num_trees,\n",
    "    max_depth=max_depth,\n",
    "    l1_regularization=l1_regul, \n",
    "    l2_regularization=l2_regul\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:65: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:491: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:907: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method CapturableResource.__del__ of <tensorflow.python.ops.boosted_trees_ops.TreeEnsemble object at 0x7fa3cb9456a0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py\", line 269, in __del__\n",
      "    with self._destruction_context():\n",
      "AttributeError: 'TreeEnsemble' object has no attribute '_destruction_context'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpejokbny3/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0 (0.398 sec)\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0 (0.182 sec)\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0 (0.184 sec)\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0 (0.181 sec)\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0 (0.179 sec)\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0 (0.188 sec)\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0 (0.180 sec)\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0 (0.182 sec)\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0 (0.183 sec)\n",
      "INFO:tensorflow:loss = 0.6931473, step = 0 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.2957\n",
      "INFO:tensorflow:loss = 0.6931473, step = 100 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 552.952\n",
      "INFO:tensorflow:loss = 0.6931473, step = 200 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 598.7\n",
      "INFO:tensorflow:loss = 0.6931473, step = 300 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 593.828\n",
      "INFO:tensorflow:loss = 0.6931473, step = 400 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 573.527\n",
      "INFO:tensorflow:loss = 0.6931473, step = 500 (0.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 568.426\n",
      "INFO:tensorflow:loss = 0.6931473, step = 600 (0.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 563.351\n",
      "INFO:tensorflow:loss = 0.6931473, step = 700 (0.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 592.464\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 800...\n",
      "INFO:tensorflow:Saving checkpoints for 800 into /tmp/tmpejokbny3/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 800...\n",
      "INFO:tensorflow:Loss for final step: 0.6931473.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.boosted_trees.BoostedTreesClassifier at 0x7fa3c6504780>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbdt_classifier.train(train_input_fn, max_steps=max_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/canned/head.py:642: auc (from tensorflow.python.ops.metrics_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The value of AUC returned by this may race with the update so this is deprecated. Please use tf.keras.metrics.AUC instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-24T09:45:58\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpejokbny3/model.ckpt-800\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method CapturableResource.__del__ of <tensorflow.python.ops.boosted_trees_ops.TreeEnsemble object at 0x7fa3b27c20b8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py\", line 269, in __del__\n",
      "    with self._destruction_context():\n",
      "AttributeError: 'TreeEnsemble' object has no attribute '_destruction_context'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 0.48577s\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-24-09:45:58\n",
      "INFO:tensorflow:Saving dict for global step 800: accuracy = 0.6311881, accuracy_baseline = 0.63118815, auc = 0.5, auc_precision_recall = 0.6844059, average_loss = 0.69314724, global_step = 800, label/mean = 0.36881188, loss = 0.69314724, precision = 0.0, prediction/mean = 0.5, recall = 0.0\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 800: /tmp/tmpejokbny3/model.ckpt-800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6311881,\n",
       " 'accuracy_baseline': 0.63118815,\n",
       " 'auc': 0.5,\n",
       " 'auc_precision_recall': 0.6844059,\n",
       " 'average_loss': 0.69314724,\n",
       " 'label/mean': 0.36881188,\n",
       " 'loss': 0.69314724,\n",
       " 'precision': 0.0,\n",
       " 'prediction/mean': 0.5,\n",
       " 'recall': 0.0,\n",
       " 'global_step': 800}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbdt_classifier.evaluate(test_train_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-24T09:45:59\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpejokbny3/model.ckpt-800\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method CapturableResource.__del__ of <tensorflow.python.ops.boosted_trees_ops.TreeEnsemble object at 0x7fa3b2563898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py\", line 269, in __del__\n",
      "    with self._destruction_context():\n",
      "AttributeError: 'TreeEnsemble' object has no attribute '_destruction_context'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 0.46106s\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-24-09:45:59\n",
      "INFO:tensorflow:Saving dict for global step 800: accuracy = 0.5588235, accuracy_baseline = 0.5588235, auc = 0.5, auc_precision_recall = 0.7205882, average_loss = 0.6931472, global_step = 800, label/mean = 0.44117647, loss = 0.6931472, precision = 0.0, prediction/mean = 0.5, recall = 0.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 800: /tmp/tmpejokbny3/model.ckpt-800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5588235,\n",
       " 'accuracy_baseline': 0.5588235,\n",
       " 'auc': 0.5,\n",
       " 'auc_precision_recall': 0.7205882,\n",
       " 'average_loss': 0.6931472,\n",
       " 'label/mean': 0.44117647,\n",
       " 'loss': 0.6931472,\n",
       " 'precision': 0.0,\n",
       " 'prediction/mean': 0.5,\n",
       " 'recall': 0.0,\n",
       " 'global_step': 800}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbdt_classifier.evaluate(test_input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBDT Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the input function.\n",
    "train_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': x_train}, y=y_train,\n",
    "    batch_size=batch_size, num_epochs=None, shuffle=True)\n",
    "test_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(\n",
    "    x={'x': x_test}, y=y_test,\n",
    "    batch_size=batch_size, num_epochs=1, shuffle=False)\n",
    "# GBDT Models from TF Estimator requires 'feature_column' data format.\n",
    "feature_columns = [tf.feature_column.numeric_column(key='x', shape=(num_features,))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpcsgx6kt2\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpcsgx6kt2', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "gbdt_regressor = tf.estimator.BoostedTreesRegressor(\n",
    "    n_batches_per_layer=num_batches_per_layer,\n",
    "    feature_columns=feature_columns, \n",
    "    learning_rate=learning_rate, \n",
    "    n_trees=num_trees,\n",
    "    max_depth=max_depth,\n",
    "    l1_regularization=l1_regul, \n",
    "    l2_regularization=l2_regul\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method CapturableResource.__del__ of <tensorflow.python.ops.boosted_trees_ops.TreeEnsemble object at 0x7fa3b248cba8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py\", line 269, in __del__\n",
      "    with self._destruction_context():\n",
      "AttributeError: 'TreeEnsemble' object has no attribute '_destruction_context'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpcsgx6kt2/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 571.1727, step = 0\n",
      "INFO:tensorflow:loss = 545.48486, step = 0 (0.336 sec)\n",
      "INFO:tensorflow:loss = 648.48956, step = 0 (0.178 sec)\n",
      "INFO:tensorflow:loss = 574.75226, step = 0 (0.180 sec)\n",
      "INFO:tensorflow:loss = 569.2014, step = 0 (0.200 sec)\n",
      "INFO:tensorflow:loss = 569.6898, step = 0 (0.192 sec)\n",
      "INFO:tensorflow:loss = 603.42944, step = 0 (0.176 sec)\n",
      "INFO:tensorflow:loss = 514.92896, step = 0 (0.195 sec)\n",
      "INFO:tensorflow:loss = 588.2447, step = 0 (0.206 sec)\n",
      "INFO:tensorflow:loss = 574.8129, step = 0 (0.205 sec)\n",
      "INFO:tensorflow:loss = 618.4296, step = 0 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 43.1398\n",
      "INFO:tensorflow:loss = 589.30444, step = 100 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.212\n",
      "INFO:tensorflow:loss = 522.8063, step = 200 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 544.195\n",
      "INFO:tensorflow:loss = 619.0401, step = 300 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 571.324\n",
      "INFO:tensorflow:loss = 577.7117, step = 400 (0.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 579.316\n",
      "INFO:tensorflow:loss = 601.4794, step = 500 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 595.22\n",
      "INFO:tensorflow:loss = 575.41235, step = 600 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 592.695\n",
      "INFO:tensorflow:loss = 582.24854, step = 700 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 594.084\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 800...\n",
      "INFO:tensorflow:Saving checkpoints for 800 into /tmp/tmpcsgx6kt2/model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 800...\n",
      "INFO:tensorflow:Loss for final step: 636.9099.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.boosted_trees.BoostedTreesRegressor at 0x7fa3b21d2860>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbdt_regressor.train(train_input_fn, max_steps=max_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-05-24T09:46:04\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpcsgx6kt2/model.ckpt-800\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method CapturableResource.__del__ of <tensorflow.python.ops.boosted_trees_ops.TreeEnsemble object at 0x7fa3b18a4320>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py\", line 269, in __del__\n",
      "    with self._destruction_context():\n",
      "AttributeError: 'TreeEnsemble' object has no attribute '_destruction_context'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 0.19375s\n",
      "INFO:tensorflow:Finished evaluation at 2021-05-24-09:46:04\n",
      "INFO:tensorflow:Saving dict for global step 800: average_loss = 615.85785, global_step = 800, label/mean = 23.078432, loss = 615.85785, prediction/mean = 0.0\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 800: /tmp/tmpcsgx6kt2/model.ckpt-800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'average_loss': 615.85785,\n",
       " 'label/mean': 23.078432,\n",
       " 'loss': 615.85785,\n",
       " 'prediction/mean': 0.0,\n",
       " 'global_step': 800}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbdt_regressor.evaluate(test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
